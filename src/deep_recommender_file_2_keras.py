# -*- coding: utf-8 -*-
"""Deep Recommender File 2 Keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uYkyjVOMiggtO99ywupg1RWdEpun0xH-
"""

import keras
import pandas as pd
import numpy as np
import keras.backend as K
from keras.layers import Input, Dense, Dropout
from keras.models import Model

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

# Remember to change to autoencoder

json_file = open('model1.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
autoencoder = keras.models.model_from_json(loaded_model_json)
autoencoder.load_weights("weights.h5")
print("Loaded model from disk")

def masked_mean_squared_loss(y_true, y_pred):
  mask = K.tf.cast(y_true >= 1.0e-09, dtype = K.tf.float32)
  num_ratings = K.sum(mask)
  return K.mean(K.tf.scalar_mul(1/num_ratings, K.tf.multiply(mask, K.tf.square(K.tf.subtract(y_true, y_pred)))))

# input_layer_com = Input(shape = (1024,))

# compressor = Dense(1024, activation = 'selu')(input_layer_com)

# encoder_1 = Dense(512, activation = 'selu')(compressor)

# encoder_2 = Dense(256, activation = 'selu')(encoder_1)

# dropout = Dropout(0.5)(encoder_2)

# decoder_1 = Dense(512, activation = 'selu')(dropout)

# decoder_2 = Dense(1024, activation = 'selu')(decoder_1)

# decompressor = Dense(1024, activation = 'selu')(decoder_2)

# deeprec = Model(input_layer_com, decompressor)

input_layer_com = Input(shape = (1024,))

compressor = Dense(1024, activation = 'selu')(input_layer_com)

compressor_model = Model(input_layer_com, compressor)

input_layer_dec = Input(shape = (1024,))

decompressor = Dense(1024, activation = 'selu')(input_layer_dec)

decompressor_model = Model(input_layer_dec, decompressor)

autoencoder.trainable = False

top_model = Model(inputs = compressor_model.input, outputs = autoencoder(compressor_model.output))

deeprec = Model(inputs = top_model.input, outputs = decompressor_model(top_model.output))

opt = keras.optimizers.SGD(lr = 0.1, decay = 1.0e-6, momentum = 0.9, nesterov = True)

deeprec.compile(loss = masked_mean_squared_loss, optimizer = opt)

def fetch_data(mode = "train"):
  
  data = pd.read_csv("/path/to/file")
  
  if(mode == "train"):
    
    return np.array(data[:][0:480000].values)
    
  else:
    
    return np.array(data[:][480001:480189].values)

for i in range(5): # Epochs
  
  x_train = fetch_data()
  
  x_test = fetch_data(mode = 'test')
  
  for i in range(10): # Iterations
    
    deeprec.fit(x_train, x_train,  epochs = 1, batch_size = 128, shuffle = True, validation_data = (x_test, x_test))
    
    x_train = autoencoder.predict(x_train)

model_json = compressor_model.to_json()
with open("compressor.json","w") as json_file:
     json_file.write(model_json)

files.download("compressor.json")
autoencoder.save('compressor.h5')
files.download('compressor.h5')

model_json = decompressor_model.to_json()
with open("decompressor.json","w") as json_file:
     json_file.write(model_json)

files.download("decompressor.json")
autoencoder.save('decompressor.h5')
files.download('decompressor.h5')